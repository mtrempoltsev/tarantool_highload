### Асинхронная обработка

![image](https://user-images.githubusercontent.com/8830475/112840431-005e0800-90a8-11eb-865c-52acc7c03501.png)

Начать стоит с простого примера: у нас есть e-mail рассылка и у нас есть пользователи, которые
должны получить уведомления от нашего сайта, например, о появлении записи в блоге,
на который они подписаны. Отправить одновременно несколько тысяч или миллионов сообщений
невозможно - мы просто положим наш почтовый сервер.
Также не имеет особого смысла получит наш пользователь уведомление сейчас или
спустя 2-3 минуты.

![image](https://user-images.githubusercontent.com/8830475/112845852-ffc87000-90ad-11eb-9d2c-eae1f82e6a62.png)

Это пример асинхронного взаимодействия - у нас есть некая очередь,
из которой мы что-то забираем и отправляем. Самое важное, конечно то,
что самое естественное состояние очереди - быть пустой (к этому мы должны стремиться,
не допуская неограниченного роста).

В нашей очереди есть сущности, которые что-то складывают в неё - producer
и сущности, которые вычитывают - consumer. В примере выше у нас был всего один
почтовый сервер, но ничто не мешало бы добавить ещё один и тем самым масштабировать
нашу систему. В дальнейшем ничто не мешает нам обобщить пример и сказать,
что в работать с очередью может кто угодно - отправка смс-сообщений,
система для сжатия картинок...

![image](https://user-images.githubusercontent.com/8830475/112841947-bd049900-90a9-11eb-8b95-86b463c389ac.png)

#### Message Queue vs. Message Broker

Часто встречаются такие определения "очередь сообщений" и "брокер сообщений", разберемся в чем разница.

- Очередь сообщений - просто контейнер, структура, хранящая какие-то данные.
Нет логики для обработки сообщений в очереди, и мы не говорим о том, как именно данные
туда доставляются или оттуда забираются.

- Брокер сообщений - система над очередью сообщений, которая отвечает и за транспорт,
и за логику, и за распределение сообщений между бизнес-системами.

#### Семантика доставки

Вернемся к примеру с почтовой рассылкой. Что будет, если по какой-то причине мы отправим
одно и тоже письмо дважды? Пользователь скорее всего проигнорирует его, и ничего
страшного не случиться. Если же мы работали с деньгами, то произошло
бы два списание/пополнения средств - это уже проблема.

Но что произойдет, если мы совсем не отправим сообщение?
С почтовой рассылкой по-прежнему скорее всего ничего страшного.
Если это СМС-рассылка о смене тарифа у пользователя?
Или пользователь подключил уведомления, заплатил за них, но
мы не прислали его - тоже проблема.

Здесь мы подошли к требованиям к нашей системе и познакомились (хоть и неявно)
с семантиками доставки:

* At least once (1+)
* At most once (0, 1)
* Exactly once (1)

Обеспечение семантики доставки "exactly once" является тут самым
трудным, хотя и в иных системах необходимым.

#### Apache Kafka

Пожалуй, самым известным брокером сообщений является Apache Kafka.

![image](https://user-images.githubusercontent.com/8830475/112846491-c93f2500-90ae-11eb-8401-146866049559.png)

Отдельный сервер Кафки именуется брокером. Брокеры образуют собой кластер,
в котором один из этих брокеров выступает контроллером,
берущим на себя некоторые административные операции.

За выбор брокера-контроллера, в свою очередь, отвечает отдельный сервис – ZooKeeper,
который также осуществляет service discovery брокеров,
хранит конфигурации и принимает участие в распределении новых читателей по брокерам и в большинстве случаев хранит
информацию о последнем прочитанном сообщении для каждого из читателей.
Это важный момент, изучение которого требует опуститься на уровень ниже и рассмотреть,
как отдельный брокер устроен внутри.

##### Commit log

Структура данных, лежащая в основе Kafka, называется commit log или журнал фиксации изменений.

![image](https://user-images.githubusercontent.com/8830475/112847064-5bdfc400-90af-11eb-974b-e84db19d74f2.png)

Новые элементы, добавляемые в commit log, помещаются строго в конец, и их порядок после этого не меняется,
благодаря чему в каждом отдельном журнале элементы всегда расположены в порядке их добавления.

Свойство упорядоченности журнала фиксаций позволяет использовать его, например, для репликации по принципу eventual
consistency между репликами БД: в них хранят журнал изменений, производимых над данными в мастер-ноде,
последовательное применение которых на слейв-нодах позволяет привести данные в них к согласованному с мастером виду.
В Кафке эти журналы называются партициями, а данные, хранимые в них, называются сообщениями.

Что такое сообщение? Это основная единица данных в Kafka, представляющая из себя просто набор байт,
в котором вы можете передавать произвольную информацию – ее содержимое и структура не имеют значения для Kafka.
Сообщение может содержать в себе ключ, так же представляющий из себя набор байт.
Ключ позволяет получить больше контроля над механизмом распределения сообщений по партициям.

#### Партиции и топики

![image](https://user-images.githubusercontent.com/8830475/112848352-aada2900-90b0-11eb-9338-ea2f891568e0.png)

Так вот в Кафке функцию очереди выполняет не партиция, а topic.
Он нужен для объединения нескольких партиций в общий поток.
Сами же партиции, как мы сказали ранее, хранят сообщения в упорядоченном виде согласно структуре данных commit log.
Таким образом, сообщение, относящееся к одному топику, может хранится в двух разных партициях,
из которых читатели могут вытаскивать их по запросу.

Следовательно, единицей параллелизма в Кафке выступает не топик, а партиция.
За счет этого Кафка может обрабатывать разные сообщения, относящиеся к одному топику,
на нескольких брокерах одновременно, а также реплицировать не весь топик целиком, а только отдельные партиции,
предоставляя дополнительную гибкость и возможности для масштабирования.

#### Pull и Push

Обратите внимание, что я не случайно использовал слово “вытаскивает” по отношению к читателю.
В описанных ранее брокерах доставка сообщений осуществляется путем их проталкивания (push) получателям через условную трубу в виде очереди.
В Кафке процесса доставки как такового нет: каждый читатель сам ответственен за вытягивание (pull) сообщений из партиций, которые он читает.

![image](https://user-images.githubusercontent.com/8830475/112848605-eecd2e00-90b0-11eb-8d7b-b81d4778e5b8.png)

Производители, формируя сообщения, прикрепляют к нему ключ и номер партиции. Номер партиции может быть выбран рандомно (round-robin), если у сообщения отсутствует ключ.

Если вам нужен больший контроль, к сообщению можно прикрепить ключ, а затем использовать hash-функцию или написать свой алгоритм, по которому будет выбираться партиция для сообщения. После формирования, производитель отправляет сообщение в Кафку, которая сохраняет его на диск, помечая, к какой партиции оно относится.

Каждый получатель закреплен за определенной партицией (или за несколькими партициями) в интересующем его топике, и при появлении нового сообщения получает сигнал на вычитывание следующего элемента в commit log, при этом отмечая, какое последнее сообщение он прочитал. Таким образом при переподключении он будет знать, какое сообщение ему вычитать следующим.

#### Consumer Group

Чтобы избежать ситуации с чтением одной партиции конкурентными читателями,
в Кафке принято объединять несколько реплик одного сервиса в consumer Group,
в рамках которого Zookeeper будет назначать одной партиции не более одного читателя.

Так как читатели привязываются непосредственно к партиции
(при этом читатель обычно ничего не знает о количестве партиций в топике),
ZooKeeper при подключении нового читателя производит перераспределение участников в Consumer Group таким образом,
чтобы каждая партиция имела одного и только одного читателя.
Читатель обозначает свою Consumer Group при подключении к Kafka.

![image](https://user-images.githubusercontent.com/8830475/112849018-53888880-90b1-11eb-8c8a-1c282aedc13e.png)

В то же время ничего не мешает вам повесить на одну партицию несколько читателей с разной логикой обработки. Например вы храните в топике список событий по действиям пользователей и хотите использовать эти события для формирования нескольких представлений одних и тех же данных и последующей отправкой их в соответствующие хранилища.

Но здесь мы можем столкнуться с другой проблемой, порожденной тем, что Кафка использует структуру из топиков и партиций. Я напомню, что Кафка не гарантирует упорядоченность сообщений в рамках топика, только в рамках партиции, что может оказаться критичным, например, при формировании отчетов о действиях по пользователю и отправке их в хранилище as is.

![image](https://user-images.githubusercontent.com/8830475/112849138-70bd5700-90b1-11eb-9e94-d8ae1ddd59c5.png)

Чтобы решить эту проблему, мы можем пойти от обратного: если все события, относящиеся к одной сущности (например, все действия относящиеся к одному user_id), будут всегда добавляться в одну и ту же партицию, они будут упорядочены в рамках топика просто потому, что находятся в одной партиции, порядок внутри которой гарантирован Кафкой.
Для этого нам и нужен ключ у сообщений: например, если мы будем использовать для выбора партиции, в которую будет добавлено сообщение, алгоритм, вычисляющий хэш от ключа, то сообщения с одинаковым ключом будут гарантированно попадать в одну партицию, а значит и вытаскивать получатель сообщения с одинаковым ключом в порядке их добавления в топик.
В кейсе с потоком событий о действиях пользователей ключом партицирования может выступать user_id.

### Очередь в Tarantool

Применение Tarantool как очереди довольно частый кейс.
Сама по себе структура хранения (B-TREE) в совокупности с возможностью писать логику
позволяет хранить в упорядоченном виде данные и обрабатывать их так,
чтобы можно было организовывать различные очереди - с приоритетами, таймаутами и т.д.

Есть несколько активно используемых реализаций:
  - [tarantool/queue](https://github.com/tarantool/queue)
  - [moonlibs/xqueue](https://github.com/moonlibs/xqueue)
  - [tarantool/sharded-queue](https://github.com/tarantool/sharded-queue) - попытка написать распределенную очередь
поверх vshard.

```lua
box.cfg{}
queue = require('queue')
-- Queue types: "fifo", "fifottl", "limfifottl", "utubettl"
queue.create_tube('my_tube', 'fifo', {temporary = true})
queue.tube.my_tube:put({'my_tube'})
---
- [0, 'r', ['message']]
...
queue.tube.my_tube:take()
---
- [0, 't', ['message']]
...
```

## Кэширование

В сфере вычислительной обработки данных кэш – это высокоскоростной уровень хранения,
на котором требуемый набор данных, как правило, временного характера.
Доступ к данным на этом уровне осуществляется значительно быстрее, чем к основному месту их хранения.
С помощью кэширования становится возможным эффективное повторное использование ранее полученных или вычисленных данных.

Данные в кэше обычно хранятся на устройстве с быстрым доступом,
таком как ОЗУ (оперативное запоминающее устройство),
и могут использоваться совместно с программными компонентами.
Основная функция кэша – ускорение процесса извлечения данных.
Он избавляет от необходимости обращаться к менее скоростному базовому уровню хранения.

Пример приложения без кэширования.
![image](https://user-images.githubusercontent.com/8830475/113515136-51c03880-957b-11eb-9896-503a350915e6.png)

При добавлении кэширования.
![image](https://user-images.githubusercontent.com/8830475/113515167-787e6f00-957b-11eb-9472-498b49abf023.png)

Основная проблема кэширования - инвалидация кэша.

### Memcached

Memcached – это удобное высокопроизводительное хранилище данных в памяти.
Memcached широко применяется для поддержки рекламных технологий, площадок интернет-коммерции, игровых, мобильных и интернет-приложений, а также других приложений, работающих в режиме реального времени.

Memcached сохраняет данные в оперативной памяти.
Поскольку Memcached, как и другие хранилища данных типа «ключ-значение» в памяти,
не нуждается в доступе к диску, это исключает задержки, связанные с поиском, и обеспечивает доступ к данным за микросекунды.
Кроме того, хранилище Memcached является распределенным, поэтому его можно просто масштабировать путем добавления новых узлов.
Многопоточность Memcached позволяет быстро наращивать вычислительную мощность.
Благодаря высокой скорости, масштабируемости, простоте, эффективности управления памятью и поддержке API для большинства распространенных языков программирования Memcached широко применяется для создания масштабного кэша с высокой производительностью.

Основные аттрибуты, которые задаются данным в кеше:

| Аттрибут |                                     Описание                                      |
|----------|:---------------------------------------------------------------------------------:|
| key      |                      имя ключа, максимальная длина 250 байт                       |
| flag     |              32-х битная целочисленное, обычно можно установить в 0               |
| exptime  |             время жизни объекта в кеше в секундах — 0 хранить всегда              |
| bytes    |          кол-во байт, которые необходимо выделить для хранения значения           |
| noreply  | опциональный параметр, что бы сервер не оптравлял ответа после выполнения запроса |
| value    |                    значение, которое необходимо добавить в кеш                    |

Команды:

* set
* get
* add
* delete

#### Memcached protocol

Memcached протокол является текстовым, что позволяет писать свои реализации
данного протокола на различных языках программирования.
В том числе и для Tarantool существует реализация memcached протокола -
https://github.com/tarantool/memcached.

#### Кэширование в Tarantool

Часто Tarantool используют не только в качестве основного
хранилища данных, но и в качестве кэша.
Схема взаимодействия в таком случае довольно прозрачна.
Допустим, основные данные лежат в PostgreSQL - перед походом
мы проверяем, не лежит ли значение в Tarantool: если да, то
сразу отдаем его пользователю, если нет, то идем в основное хранилище,
но перед выдачей результата пользователю сохраняем его в Tarantool.
Всё взаимодействие в таком случае происходит через коннектор на
каком-либо языке, чтобы не терять в производительности на сериализацию
данных в Lua.

Для инвалидации кэша пользователю всё-таки придется написать
какую-то логику. Но обычно, если это инвалидация по времени,
то существуют готовые модули, которые в бэкграунде
проходят по спейсу и удаляют кортежи, удовлетворяющие
определенному условию:
  - [tarantool/expirationd](https://github.com/tarantool/expirationd)
  - [moonlibs/indexpiration](https://github.com/moonlibs/indexpiration)
  - [sonntex/tarantool-capped-expirationd](https://github.com/sonntex/tarantool-capped-expirationd) - expirationd на С.

### Домашнее задание

Написать очередь (семантика доставки at least once):
  - queue.new(opts) - создание очереди (должна быть возможность указать движок хранения);
  - queue.get(name) - получить экземпляр очереди;
  - queue_obj:grant(...) - выдача прав на использование очереди;
  - queue_obj:put(data) - положить сообщение в очередь;
  - queue_obj:take({timeout}) - получить сообщение из очереди. Если очередь пустая, то ждать timeout до получения сообщения.
    Вернуть nil - если пустая;
  - queue_obj:stats() - Получение статистики по очереди (PUT/TAKE/LISTENERS).

Тесты можно написать с помощью luatest.
