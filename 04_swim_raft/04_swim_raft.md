## SWIM

### Gossip-протоколы

Одной из проблем, возникающей при работе с распределенными системами
является достижение консенсуса.
Т.е. возможность принятия одного решения всеми узлами кластера.
Но, кроме этого, перед нами стоит и другая проблема — обнаружение отказов
в распределенных системах.
Мы не застрахованы от проблем с электричеством, оборудованием, программным
обеспечением и т.д. Поэтому необходимо своевременно обнаруживать отказы
узлов кластера и как-то на них реагировать: исправлять, выводить из кластера,
добавлять новые узлы...
Нам необходим алгоритм, который бы мог всё это делать.
Решением "в лоб" является широковещательная рассылка сообщений всем узлам кластера.
Однако это создает проблемы масштабирования нашей системы -
у таких алгоритмов квадратичная сложность, которая создает
нежелательную нагрузку на сеть. Поэтому с такими алгоритмами обычно
никто не работает.
Вместо этого предлагается использовать т.н. "gossip"-алгоритмы -
алгоритмы распространения слухов.
![image](https://user-images.githubusercontent.com/8830475/108864759-90211a00-7603-11eb-93d7-c458188daeda.png)

Данные алгоритмы дают линейную нагрузку на сеть и
в общем случае позволяют распространять любую информацию
в кластере. Однако обычно нас интересует именно обнаружение отказов.

![image](https://user-images.githubusercontent.com/8830475/108866233-0e31f080-7605-11eb-8327-5370eed87dff.png)

Также при использовании протокола UDP мы не можем быть уверены,
что наш PING будет доставлен. Кроме этого, сеть между узлами может
быть повреждена - в случае прямых пингов узлы думали, что те,
кому они не смогли отправить PING не работают.
По факту же между узлами просто нет сети.
Решить данную проблему можно с помощью непрямых (indirect) PING'ов.

![image](https://user-images.githubusercontent.com/8830475/108866468-4a655100-7605-11eb-872a-279ad6d12d61.png)

Гарантии, которые обычно дают нам данные протоколы:
  * Константное время получение информации хотя бы одним узлом - O(1)
  * Логарифмическое время распространения информации по всему кластеру - O(lnN)
N - количество узлов в кластере.

![image](https://user-images.githubusercontent.com/8830475/108867895-b5fbee00-7606-11eb-82f7-21a59efd360d.png)


### SWIM (Scalable Weakly-consistent Infection-style Process Group Membership Protocol)

* Scalable - как и любой gossip-протокол SWIM хорошо масштабируется;
* Weakly-consistent - между узлами нет явной синхронизации; узлы рано или поздно синхронизуются с помощью слухов;
* Infection-style Process - "gossip";
* Group Membership - каждый узел имеет список узлов, которые его видят.

В нормально функционирующем SWIM'e узлы просто отправляют друг другу PING'и.
Узлы считаются живыми - "alive".
Однако если в какой-то момент один узел не ответил на PING, он становится подозрительным -
"suspected". Нода обращается к соседним нодам с просьбой пингануть данный узел.
Если хотя бы одна нода смогла пингануть данный узел, слух не подтверждается.
Ввиду нестабильности UDP (потеря пакетов нормальна), узел даже не сразу
будет считаться мертвым - "dead". Какое-то время его ещё будут пытаться пинговать.

![image](https://user-images.githubusercontent.com/8830475/108868977-ccef1000-7607-11eb-94fe-b4fa34ef16fc.png)

### Инкарнация

Инкарнация состоит из двух частей - generation и version.
Generation - персистентная часть инкарнации, пользователь может задавать её
вручную (по умолчанию используется время в момент создания инстанса).
Version - часть, которая изменяется автоматически — увеличивается при
некоторых событиях.

![image](https://user-images.githubusercontent.com/8830475/108869689-7afaba00-7608-11eb-941b-8a56ec2ad2c6.png)

Допустим, у нас есть 3 узла. Узел B отказал. И узел A считает узел B мертвым, а
узел С считает B живым.
Они обмениваются этой информацией. Предполагается худшее — узел С начнет считать B
мертвым.
При этом, если B начнет слать "опровержения" слухов,
никто ему верить не будет - мы не знаем, действительно ли узел B жив или
это старые затерявшиеся UDP пакеты начали до нас доходить.

Для опровержения слухов B, если поймет, что его считают мертвым,
должен будет увеличивать счетчик инкарнации (а конкретно версию).
Увеличение generation будет свидетельствовать, например, о том,
что инстанс перезапустили — при этом UDP пакеты,
отправленные предыдущей версией будут отбрасываться.

![image](https://user-images.githubusercontent.com/8830475/108870699-65d25b00-7609-11eb-9d88-570682f6e3bc.png)

Несколько выводов из вышесказанного:
  * Инкарнация необходима для опровержения ложных слухов
  * Используется, в том числе, и как защита от проблем с UDP
  * Если слухи равны — предполагаем худшее

#### Реализация в Tarantool (встроенный модуль SWIM)

Сам по себе алгоритм достаточно простой, однако при реализации в Tarantool он имеет несколько особенностей:
  * Работа делится на раунды — нет "честной" рандомизации, есть "справедливая".
В начале "раунда" таблица участников перемешивается и далее в соответствии с получившейся
очередью рассылаются PING'и;
  * Адресация узлов по UUID. Т.е. uri, IP, port - можно менять;
  * Реализован на C, но доступен в виде Lua-модуля.

#### Антиэнтропия

Мы рассмотрели случай отказа узлов, но в общем случае SWIM
подходит для распространения информации о событиях в кластере.
Допустим, у нас было 2 узла, и мы добавили третий.
Теперь узел B знает про A и С, С знает про B, а А только про B.
Как теперь узлу A узнать про C? B должен сообщить A о новом узле,
но у нас нет гарантии, что это сообщение когда-либо дойдет.
Кроме этого, событие будет распространяться
в течение ограниченного времени — не бесконечно.
В таком случае возможна ситуация, что узел А так никогда не узнает про С.

Решение — антиэнтропия.
Мы добавляем в UDP-пакет некоторую часть таблицы участников кластера.
Таким образом рано или поздно узел А узнает об узле C.
Работает данная возможность автоматически и не требует никакой настройки.

![image](https://user-images.githubusercontent.com/8830475/108873118-ed20ce00-760b-11eb-8601-5a56eb94fde1.png)

#### Payload

Возможность передавать некоторую полезную информацию по UDP.
Например, адрес узла для подключения по TCP.
Payload ограничен по размеру — работаем с UDP.

#### Шифрование

SWIM можно использовать в любой открытой сети, а передаваемый трафик шифровать.
Ключи шифрования необходимо указывать самостоятельно для каждого узла.

#### Выход из кластера

Если узел выводят из кластера, то в оригинальном SWIM
узел, перед тем, как считаться мертвым должны будут пингануть,
признать мертвым - т.е. это продолжительный процесс.
Однако если мы руками выводим ноду из кластера и не хотим создавать
лишних слухов, есть возможность сделать это "вежливо".

### Демонстрация

Запустим следующий код
```lua
-- tarantool -i init.lua {3301,3302,3303}

local port = tonumber(arg[1])
if port == nil then
    error('Invalid port')
end

_G.swim = require('swim').new()

local instance_uuid = '804f00ed-271c-47fa-844e-df4c6e0d' .. tostring(port)

_G.swim:cfg({
    uuid = instance_uuid,
    uri = port,
    heartbeat_rate = 1,
    ack_timeout = 0.1,
    gc_mode = 'off',
})

function get_members()
    local result = {}
    for k, v in _G.swim:pairs() do
        result[k] = v
    end
    return result
end
```

Здесь специально `ack_timeout` выставлен в небольшое значение (по умолчанию `30`),
чтобы эффект от манипуляций был виден сразу.
`gc_mode = 'off'` означает, что модуль не будет автоматически удалять мертвых member'ов.

Посмотрим на `get_members` на одном из инстансов.
```lua
tarantool> get_members()
---
- 804f00ed-271c-47fa-844e-df4c6e0d3303:
    uri: 127.0.0.1:3303
    status: alive
    incarnation: cdata {generation = 1614776861620271ULL, version = 0ULL}
    uuid: 804f00ed-271c-47fa-844e-df4c6e0d3303
    payload_size: 0
...
```

Попробуем добавить новых member'ов.
```lua
tarantool> swim:probe_member(3301)
---
- true
...

tarantool> swim:add_member({uuid = '804f00ed-271c-47fa-844e-df4c6e0d3302', uri = 3302})
---
- true
...

tarantool> get_members()
---
- 804f00ed-271c-47fa-844e-df4c6e0d3301:
    uri: 127.0.0.1:3301
    status: alive
    incarnation: cdata {generation = 1614776857103623ULL, version = 0ULL}
    uuid: 804f00ed-271c-47fa-844e-df4c6e0d3301
    payload_size: 0
  804f00ed-271c-47fa-844e-df4c6e0d3303:
    uri: 127.0.0.1:3303
    status: alive
    incarnation: cdata {generation = 1614776861620271ULL, version = 0ULL}
    uuid: 804f00ed-271c-47fa-844e-df4c6e0d3303
    payload_size: 0
  804f00ed-271c-47fa-844e-df4c6e0d3302:
    uri: 127.0.0.1:3302
    status: alive
    incarnation: cdata {generation = 1614776859674371ULL, version = 0ULL}
    uuid: 804f00ed-271c-47fa-844e-df4c6e0d3302
    payload_size: 0
...
```

Теперь, если вызвать `get_members` на других узлах, мы увидим такой же результат.
Здесь операция добавления нового member'a была сделана двумя разными путями.
`probe_member` принимает только uri, но не дает гарантий, что будет
что-то добавлено. Если member'a с таким uri не существует, мы всё равно получим `true`.
`add_member` принимает ещё и uuid, но добавляет member'a в таблицу даже если его физически
не существует.

Попробуем выключить одну из нод. Спустя какое-то время увидим, что `status` у этой ноды изменился на `dead`.
Если включить ноду обратно, то увидим, что она станет `alive`, при этом `generation` изменится.

Это один из примеров события. Есть и другие — например, изменение payload'a,
появление/удаление инстанса из кластера, изменение статуса...
Обрабатывать эти события можно с помощью специального триггера.
`swim:on_member_event(function(m, e) ... end)` - устанавливает функцию-обработчик,
member'a - источник события и объект-событие.

```lua
function on_event(m, e)
    if e:is_new_status() then
        print('is_new_status:', m:uuid(), m:status())
    end
    if e:is_new_uri() then
        print('is_new_uri:', m:uuid(), m:uri())
    end
    if e:is_new_incarnation() then
        print('is_new_incarnation:', m:uuid(), m:incarnation())
    end
    if e:is_new_payload() then
        print('is_new_payload:', m:uuid(), m:payload())
    end
    if e:is_drop() then
        print('is_drop:', m:uuid())
    end
end
swim:on_member_event(on_event)
```

### Модуль membership

Существует реализация протокола SWIM на чистом Lua. Она появилась исторически раньше, и
является используемой в текущих проектах.
Подробнее в репозитории [tarantool/membership](https://github.com/tarantool/membership).
Интерфейс похож на встроенный модуль, но является синглтоном — этого достаточно.

### Альтернативы

SWIM используется во многих продуктах, причем обычно с
различными улучшениями и дополнениям (часто это зависит от задачи).
Существуют и другие типы gossip-протоколов. Так, например,
Cassandra работает по похожему принципу: ноды периодически
пингуют друг друга. Однако выделяется особый класс узлов -
"seed nodes", которые служат внешними координаторами в
процессе распространения слухов и при старте кластера.

## RAFT

### Необходимость в лидере
При работе в распределенных системах пред нами достаточно остро стоит
вопрос синхронизации данных между узлами.
Начнем с репликации. Репликация — процесс синхронизации данных между несколькими
узлами. Всего существует 2 типа репликации — асинхронная и синхронная.
Асинхронная репликация не дает нам особых гарантий сохранности записанных данных.
Нам просто необходимо записать данные в локальный журнал. Далее эти данные асинхронно
реплицируются на другие узлы. При этом у нас нет гарантий, что данные-таки будут
записаны на эти узлы — сразу после подтверждения транзакции инстанс может выйти из строя,
не успев отреплицировать данные. Клиент получил ОК — транзакция закоммичена.
Но по факту со смертью узла мы потеряли эту транзакцию.

Более надежный подход — использование синхронной репликации.
Все "пишущие" транзакции приходят на инстанс-лидер. Который не просто записывает
транзакции в локальный журнал, но и дожидается, пока часть других инстансов
применит эту транзакцию у себя.

Проблемы начинаются в тот момент, когда лидер выходит из строя.
В этом случае необходимо выбрать нового лидера. Это можно делать и руками,
но всё-таки хочется это делать автоматически. Тогда нам на помощь
приходит алгоритм RAFT. Это не единственный алгоритм, как и в случае с
gossip-протоколами, существует целое семейство таких алгоритмов.

Raft включает в себя синхронную репликацию журнала и выборы с гарантией
единственности лидера на протяжении всего времени существования кластера.
Обычно кластер выглядит так: один узел находится в состоянии leader и может писать в журнал,
применять транзакции и так далее. Все остальные узлы находятся в состоянии follower и применяют всё,
что получают от лидера. Если follower получит по каналу репликации какую-то транзакцию от не-лидера,
он её проигнорирует.

Часть протокола, касающаяся репликации журнала, достаточно проста.
Текущий лидер рассылает всем членам кластера запросы AppendEntries, содержащие новые записи.
Как только более половины членов кластера успешно применят записи,
отправленные лидером, эти записи считаются подтверждёнными.

Всё время существования кластера разделено на логические блоки, называемые термами (term).
Они пронумерованы целыми числами начиная с 1, и каждый терм начинается с выборов нового лидера.
После того как лидер выбран, он принимает запросы и сохраняет в журнал новые записи,
которые рассылает остальным членам кластера.

Чтобы узел был выбран лидером, за него должны проголосовать более половины узлов в кластере.
Это гарантирует, что в каждом терме будет выбран либо единственный лидер, либо никто.
В некоторых термах выборы могут так и не закончиться назначением лидера. Такое может произойти,
если все узлы проголосовали, но ни один из кандидатов не получил большинство голосов.
В таком случае начнётся новый терм, а значит будут проведены новые выборы.
Все узлы проголосуют заново. Таким образом, рано или поздно один из узлов станет лидером.

Согласно Raft каждый узел может быть в одном из трёх состояний — **follower, candidate, leader**.

**Follower** — состояние, в котором узел может только отвечать на запросы AppendEntries
от лидера и RequestVote от кандидатов. Если follower давно не получал ничего от лидера
(в течение так называемого Election Timeout), то он переходит в состояние candidate и начинает новый терм,
а вместе с тем и новые выборы.

**Candidate** — состояние узла, инициировавшего новые выборы. В этом случае узел голосует сам за себя,
а затем рассылает всем членам кластера запросы RequestVote. Ответ на этот запрос — поле VoteGranted,
принимающее значение true, если узел проголосовал за кандидата.
Сам кандидат никогда не отвечает на запросы RequestVote других кандидатов.
Он уже проголосовал за себя и больше ни за кого не голосует.
Кандидат ведёт подсчёт отданных за него голосов. Как только их становится больше,
чем половина всех узлов в кластере, кандидат становится лидером, о чём сообщает всем рассылкой пустого запроса
AppendEntries (своеобразный хартбит, который может послать только лидер).

**Leader** — единственное состояние, в котором узел может писать в журнал.
Лидер реплицирует этот журнал с помощью запроса AppendEntries.
Кроме того, в случае, когда новые запросы не поступают, лидер периодически рассылает хартбиты
(пустые запросы AppendEntries), чтобы избежать наступления таймаута и выдвижения новых кандидатов.

![image](https://user-images.githubusercontent.com/8830475/109615037-76705d00-7b44-11eb-8647-e4742e5a1013.png)

![image](https://user-images.githubusercontent.com/8830475/109615160-9ef85700-7b44-11eb-81cc-1501e139008b.png)

![image](https://user-images.githubusercontent.com/8830475/109615208-b33c5400-7b44-11eb-9ffe-28a2455f1aa0.png)

### Визуализация

https://raft.github.io/

### RAFT в Tarantool
Для понимания того, как работает RAFT необходимо начать с синхронной реплиации.
Синхронными являются отдельные транзакции, которые затрагивают синхронные
спейсы. Спейс синхронный, если при его создании был задан флаг `is_sync = true`.
Информация об операциях над данными попадает в журнал. При этом для случая
асинхронной репликации у нас были обычные - update/delete/replace/..., то
в синхронном случае Tarantool сначала записывает транзакцию локально, потом после
получения подтверждения записывает команду - COMMIT. В случае неудачи - ROLLBACK.

Для настройки синхронной репликации у нас есть 2 опции:
```lua
box.cfg{
    replication_synchro_quorum = 'N/2 + 1',
    replication_synchro_timeout = 30,
}
```

И для настройки работы протокола RAFT - 2:
```lua
box.cfg{
    election_mode = 'off|voter|candidate',
    election_timeout = 5,
}
```

### Демонстрация
Запустим следующий скрипт на нескольких инстансах.

```lua
-- tarantool init.lua {3301,3302,3303,3304}
#!/usr/bin/env tarantool
local fio = require('fio')
local port = tonumber(arg[1])
if port == nil then
    error('Invalid port')
end

local work_dir = fio.pathjoin('data', port)
fio.mktree(work_dir)

box.cfg({
    listen = port,
    work_dir = work_dir,
    read_only = (port ~= 3301),
    replication = {'3301', '3302', '3303', '3304'},
    replication_synchro_quorum = 'N / 2 + 1',
    election_mode = 'off'
})

if port == 3301 then
    box.schema.user.passwd('admin', 'test')
    box.schema.user.grant('guest', 'replication', nil, nil, {if_not_exists=true})
    box.schema.user.grant('guest', 'read,write,execute', 'universe', nil, {if_not_exists=true})
end

require('console').start()
```

С помощью `replication={'3301', '3302', '3303', '3304'}` мы объединяем наши инстансы в один репликасет.
При этом запись возможна только на инстансе, у которого порт `3301`.
Изначально raft отключен. Включим его, вызвав на первом инстансе `box.cfg({election_mode = 'candidate'})`,
на других `box.cfg({election_mode = 'voter'})`. Спустя какое-то время первый инстанс будет выбран лидером.
Убедиться в этом можно с помощью `box.info.election`.
Теперь стоит попробовать сделать кандидатом другой инстанс, а первый выключить.
Видно, что инстанс будет переизбран новым лидером. При этом если в строй вернуть старый, то он будет иметь
состояние `follower`.

### CAP-теорема

![image](https://user-images.githubusercontent.com/8830475/109415853-2e2e2f00-79cc-11eb-8545-910a7009e6fc.png)

#### Формулировка

В распределенной системе можно обеспечить только два свойства из трех: согласованность,
доступность и устойчивость к разделению.

**Согласованность данных (consistency)** - во всех узлах в каждый момент времени данные согласованы друг с другом,
то есть не противоречат друг другу.
Если в одном из узлов в ячейке базы данных есть данные, такие же данные есть на всех остальных узлах.

**Доступность (availability)** - любой запрос может быть обработан системой, вне зависимости от ее состояния.

**Устойчивость к разделению (partition tolerance)** - расщепление системы на несколько изолированных секций
не приводит к некорректному отклику от каждой из секций: отвалилась сеть между двумя узлами,
но каждый из них может корректно отвечать своим клиентам.

Ниже представлены примеры того, что могут представлять собой системы без одного из этих свойств:

**+Availability +Consistency -Parition tolerance.**
Система, которая рассчитывает на то, что сеть абсолютно надёжна,
и благодаря этому может обеспечить консистентность данных на всех живых узлах.
Или, в вырожденном случае, система из одного узла, где неконсистентности быть не может,
и которая доступна всегда, когда доступен её узел.
Другими словами, на практике таких систем или не существует, или они не являются распределёнными.

**+Consistency +Partition tolerance -Availability.**
Система с несколькими мастер-базами, которые обновляются синхронно.
Она всегда корректна, потому что транзакция отрабатывает,
только если изменения удалось распространить по всем серверам БД.
Она продолжает корректно работать по крайней мере на чтение, если один из серверов падает.
А вот попытки записи будут обрываться или сильно задерживаться,
пока система не убедится в своей консистентности.

**+Availability +Partition tolerance -Consistency**.
Система с несколькими серверами, каждый из которых может принимать данные,
но не обязуется в тот же момент распространять их по всему кластеру.
Система переживает падения части серверов, но когда они входят в строй,
они будут выдавать пользователям старые данные.

#### На практике

![image](https://user-images.githubusercontent.com/8830475/109415918-78afab80-79cc-11eb-9fd9-6b4cd8571c11.png)


На практике при рассмотрении этой модели могут возникать проблемы.
При наличии асинхронной репликации у нас нет строгой консистентности — транзакция может быть
подтверждена, но при этом часть пользователей, запрашивающие данные с реплик всё ещё могут получать устаревшие данные.
Тогда такие системы просто P.

#### PACELC

![image](https://user-images.githubusercontent.com/8830475/109416181-ac3f0580-79cd-11eb-9e37-25be13e89504.png)

В случае разделения сети (P) в распределённой компьютерной системе необходимо выбирать между доступностью (A) и согласованностью (C) (согласно теореме CAP),
но в любом случае, даже если система работает нормально в отсутствии разделения,
нужно выбирать между задержками (L) и согласованностью (C).

Основная цель теоремы PACELC —
обратиться тезису «Игнорирование необходимости выбора между согласованностью и задержкой в реплицируемых системах является основным упущением [в рамках CAP], поскольку необходимость этого выбора присутствует при работы системы всегда, в то время как CAP имеет отношение только к дискутируемо редкому случаю разделения сети».

### Домашнее задание. Двухфазный коммит (2PC).

```
Coordinator                                          Participant
                             QUERY TO COMMIT
                 -------------------------------->
                             VOTE YES/NO             prepare*/abort*
                 <-------------------------------
commit*/abort*               COMMIT/ROLLBACK
                 -------------------------------->
                             ACKNOWLEDGMENT          commit*/abort*
                 <--------------------------------
end
```

Изменение конфигурации в распределенных системах должно происходить синхронно
и атомарно.
Одним из подходов, реализующих эту идею, является двухфазный коммит.

Один из инстансов (координатор) получает новую конфигурацию.
После этого он отправляет эту конфигурацию на каждый из инстансов кластера
для её валидации. Валидация гарантирует, что следующая фаза не закончится неудачей.

Если валидация успешна, каждый из инстансов отправляет подтверждение координатору.
После получения подтверждения от каждого инстанса координатор начинает фазу применения
конфига.

Если валидация неуспешна хоть на одном из инстансов, координатор отправляет "abort" -
остановку применения конфигурации.

В домашнем задании предлагается реализовать двухфазный коммит.

#### Условие

- Поднимите N инстансов Tarantool и присвойте каждому порядковый номер/uuid;
- На каждом инстансов поднимите HTTP - сервер, который будет возвращать свой
идентификатор на GET запрос;
- Каждый из инстансов должен быть способен выступать координатором при применении
конфигурации;
- Топология: адреса, порты, логины и пароли должны быть собраны в
конфигурационном файле;
- (*) Не хранить логины и пароли для доступа в конфигурационном файле,
использовать для распространения этой информации модуль swim.

Применение конфигурации - изменение порта, который слушает сервер
(старый сервер при этом необходимо будет выключить):
```
{
   [1] = '8080',
   [2] = '8083',
   [3] = '8082',
   [4] = box.NULL, -- отключение сервера
}
```

На стадии валидации каждый из серверов проверяет,
сможет ли он слушать данный порт или нет.

Небольшая подсказка, как это можно проверить:
```lua
local socket = require('socket')
local function can_use_port(port)
    local sock = socket('AF_INET', 'SOCK_STREAM', 'tcp')
    local ok = sock:bind('0.0.0.0', port)
    local err = sock:error()
    sock:close()
    if not ok then
        return false, err
    end
    return true
end
```

Подумайте о том, какие ещё случаи стоило бы валидировать,
кроме очевидного "порт слушает кто-то другой".

В случае успеха на стадии "commit" отключаем старый сервер, включаем новый.
В случае неудачи пишем в лог "Failed to change port from <old_port> to <new_port>".

Если адрес не изменяется или инстанс не указан в конфиге,
никаких действий делать не нужно.

Стоит подумать и над ситуацией, когда порт должен быть свободным,
но предыдущий владелец ещё не успел его освободить.

Рекомендация: не стоит устанавливать соединения между инстансами прямо на старте.
Делайте это при необходимости.
